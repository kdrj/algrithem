Kafka中的Message是以topic为基本单位组织的，不同的topic之间是相互独立的。每个topic又可以分成几个不同的partition
(每个topic有几个partition是在创建topic时指定的)，每个partition存储一部分Message

partition是以文件的形式存储在文件系统中，比如，创建了一个名为page_visits的topic，其有5个partition，那么在Kafka的数据目录中
(由配置文件中的log.dirs指定的)中就有这样5个目录: page_visits-0， page_visits-1，page_visits-2，page_visits-3，page_visits-4，
其命名规则为<topic_name>-<partition_id>，里面存储的分别就是这5个partition的数据。

Partition中的每条Message由offset来表示它在这个partition中的偏移量，这个offset不是该Message在partition数据文件中的实际存储位置，而是逻辑上一个值，
它唯一确定了partition中的一条Message。因此，可以认为offset是partition中Message的id。

partition中的每条Message包含了以下三个属性：
     1.offset
     2.MessageSize
     3.data
     其中offset为long型，MessageSize为int32，表示data有多大，data为message的具体内容。它的格式和Kafka通讯协议中介绍的MessageSet格式是一致。


Kafka解决查询效率的手段之一是将数据文件分段，比如有100条Message，它们的offset是从0到99。假设将数据文件分成5段，第一段为0-19，第二段为20-39，
以此类推，每段放在一个单独的数据文件里面，数据文件以该段中最小的offset命名。这样在查找指定offset的Message的时候，
用二分查找就可以定位到该Message在哪个段中。
Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为.index


-------------
https://blog.csdn.net/gududedabai/article/details/80001523
-------------


........................................................... 

 <<<<<<<<<<<  kafka message 格式是什么样的?  >>>>>>>>>>>>>>>>>>>
一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成

header部分由一个字节的magic(文件格式)和四个字节的CRC32(用于判断body消息体是否正常)构成。

当magic的值为1的时候，会在magic和crc32之间多一个字节的数据：attributes(保存一些相关属性，比如是否压缩、压缩格式等等);

如果magic的值为0，那么不存在attributes属性

body是由N个字节构成的一个消息体，包含了具体的key/value消息
.............................


查看kafka版本命令:  find ./libs/ -name \*kafka_\* | head -1 | grep -o '\kafka[^\n]*' 

<<<<<<<<<<<<<<<   zookeeper在Kakfa中扮演的角色  >>>>>>>>>>>>>>>>>>>>>>>
Kafka将元数据信息保存在Zookeeper中，但是发送给Topic本身的数据是不会发到Zk上的，否则Zk就疯了。
kafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置。
broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新。
而客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整。
这样就保证了添加或去除broker时，各broker间仍能自动实现负载均衡。
这里的客户端指的是Kafka的消息生产端(Producer)和消息消费端(Consumer)Producer端使用zookeeper用来"发现"broker列表,
以及和Topic下每个partition的leader建立socket连接并发送消息。
也就是说每个Topic的partition是由Lead角色的Broker端使用zookeeper来注册broker信息,
以及监测partition leader存活性.Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,
同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息.
2.zookeeper中信息
![Aaron Swartz](2779043-ace9980fad0c49a4.png)




kafka项目启动报错： Error processing condition on org.springframework.boot.autoconfigure.kafka.KafkaAutoCon
启动时遇见报错

想到spring boot与kafka的兼容问题

原因：spring-boot 我用的是 2.0.0

改成 1.5.6 就可以了

<parent>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-parent</artifactId>
       <version>1.5.6.RELEASE</version>
   <relativePath/> <!-- lookup parent from repository -->
</parent>




kafka websocket 整合

<?xml version="1.0" encoding="UTF-8"?>
 2 <project xmlns="http://maven.apache.org/POM/4.0.0"
 3          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 4          xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
 5     <modelVersion>4.0.0</modelVersion>
 6 
 7     <groupId>person</groupId>
 8     <artifactId>wbSocketkafka</artifactId>
 9     <version>1.0-SNAPSHOT</version>
10 
11     <dependencies>
12         <!-- webSocket所需依赖 -->
13         <dependency>
14             <groupId>javax</groupId>
15             <artifactId>javaee-api</artifactId>
16             <version>7.0</version>
17         </dependency>
18         <!-- kafka 所需依赖 -->
19         <dependency>
20             <groupId>org.apache.kafka</groupId>
21             <artifactId>kafka_2.9.2</artifactId>
22             <version>0.8.1.1</version>
23         </dependency>
24         <dependency>
25             <groupId>org.apache.kafka</groupId>
26             <artifactId>kafka-clients</artifactId>
27             <version>RELEASE</version>
28         </dependency> 
29     </dependencies>
30 </project>


//此处定义接口的uri
 2 @ServerEndpoint("/wbSocket")
 3 public class WebSocket {
 4     private Session session;
 5     public static CopyOnWriteArraySet<WebSocket> wbSockets = new CopyOnWriteArraySet<WebSocket>(); //此处定义静态变量，以在其他方法中获取到所有连接
 6     
 7     /**
 8      * 建立连接。
 9      * 建立连接时入参为session
10      */
11     @OnOpen
12     public void onOpen(Session session){
13         this.session = session;
14         wbSockets.add(this); //将此对象存入集合中以在之后广播用，如果要实现一对一订阅，则类型对应为Map。由于这里广播就可以了随意用Set
15         System.out.println("New session insert,sessionId is "+ session.getId());
16     }
17     /**
18      * 关闭连接
19      */
20     @OnClose
21     public void onClose(){
22         wbSockets.remove(this);//将socket对象从集合中移除，以便广播时不发送次连接。如果不移除会报错(需要测试)
23         System.out.println("A session insert,sessionId is "+ session.getId());
24     }
25     /**
26      * 接收前端传过来的数据。
27      * 虽然在实现推送逻辑中并不需要接收前端数据，但是作为一个webSocket的教程或叫备忘，还是将接收数据的逻辑加上了。
28      */
29     @OnMessage
30     public void onMessage(String message ,Session session){
31         System.out.println(message + "from " + session.getId());
32     }
33 
34     public void sendMessage(String message) throws IOException {
35         this.session.getBasicRemote().sendText(message);
36     }
37 }

public class ConsumerKafka extends Thread {
 2 
 3     private KafkaConsumer<String,String> consumer;
 4     private String topic = "kafkaTopic";
 5 
 6     public ConsumerKafka(){
 7 
 8     }
 9 
10     @Override
11     public void run(){
12         //加载kafka消费者参数
13         Properties props = new Properties();
14         props.put("bootstrap.servers", "localhost:9092");
15         props.put("group.id", "ytna");
16         props.put("enable.auto.commit", "true");
17         props.put("auto.commit.interval.ms", "1000");
18         props.put("session.timeout.ms", "15000");
19         props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
20         props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
21         //创建消费者对象
22         consumer = new KafkaConsumer<String,String>(props);
23         consumer.subscribe(Arrays.asList(this.topic));
24         //死循环，持续消费kafka
25         while (true){
26             try {
27                //消费数据，并设置超时时间
28                 ConsumerRecords<String, String> records = consumer.poll(100);
29                 //Consumer message
30                 for (ConsumerRecord<String, String> record : records) {
31                     //Send message to every client
32                     for (WebSocket webSocket :wbSockets){
33                         webSocket.sendMessage(record.value());
34                     }
35                 }
36             }catch (IOException e){
37                 System.out.println(e.getMessage());
38                 continue;
39             }
40         }
41     }
42 
43     public void close() {
44         try {
45             consumer.close();
46         } catch (Exception e) {
47             System.out.println(e.getMessage());
48         }
49     }
50 
51     //供测试用，若通过tomcat启动需通过其他方法启动线程
52     public static void main(String[] args){
53         ConsumerKafka consumerKafka = new ConsumerKafka();
54         consumerKafka.start();
55     }
56 }

<!DOCTYPE html>
 2 <html lang="en">
 3 <head>
 4     <meta charset="UTF-8">
 5     <title>WebSocket client</title>
 6     <script type="text/javascript">
 7         var socket;
 8         if (typeof (WebSocket) == "undefined"){
 9             alert("This explorer don't support WebSocket")
10         }
11 
12         function connect() {
13             //Connect WebSocket server
14             socket =new WebSocket("ws://127.0.0.1:8080/wbSocket");
15             //open
16             socket.onopen = function () {
17                 alert("WebSocket is open");
18             }
19             //Get message
20             socket.onmessage = function (msg) {
21                 alert("Message is " + msg);
22             }
23             //close
24             socket.onclose = function () {
25                 alert("WebSocket is closed");
26             }
27             //error
28             socket.onerror = function (e) {
29                 alert("Error is " + e);
30             }
31         }
32 
33         function close() {
34             socket.close();
35         }
36 
37         function sendMsg() {
38             socket.send("This is a client message ");
39         }
40     </script>
41 </head>
42 <body>
43     <button onclick="connect()">connect</button>
44     <button onclick="close()">close</button>
45     <button onclick="sendMsg()">sendMsg</button>
46 </body>
47 </html>
 
