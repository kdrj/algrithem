Kafka是分布式发布-订阅消息系统,主要用于处理流式数据。

为什么要用消息队列
     1.缓冲和削峰  2.解耦和扩展性  3.冗余  4.健壮性  5.异步通信


ISR:In-Sync Replicas 副本同步队列
AR:Assigned Replicas 所有副本

broker 是消息的代理
producer : 生产者
consumer : 消费者
Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉取指定Topic的消息，broker在中间起到一个代理保存消息的中转站。

kafka中的 zookeeper 起到什么作用
zookeeper 是一个分布式的协调组件，早期版本的kafka用zk做meta信息存储，consumer的消费状态，group的管理以及 offset的值。
考虑到zk本身的一些因素以及整个架构较大概率存在单点问题，新版本中逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的group coordination协议，
也减少了对zookeeper的依赖。但是broker依然依赖于ZK，zookeeper 在kafka中还用来选举controller 和 检测broker是否存活等等


>>>>>>>>>>>>>>>>>>>>>>>>>      kafka创建topic           <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
    bin/kafka-topics --zookeeper localhost:2181 --create --topic normal-topic --partitions 2 --replication-factor 1
 生产者：
    ./bin/kafka-console-producer.sh --broker-list ip:6667 --topic topicname
 消费者
    ./bin/kafka-console-consumer.sh --bootstrap-server ip:6667,ip:6667.. --topic topicname --from-beginning

 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>消费者注册到kafka有多种方式<<<<<<<<<<<<<<<<<<<<<<<
    (1)subscribe:这种方式在新增topic或者partition或者消费者增加或者消费者减少的时候，会进行消费者组内消费者的再平衡。
    (2)assign:这种方式注册的消费者不会进行rebalance。

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Consumer有三种消费交付语义<<<<<<<<<<<<<<<<<<<<<<<<<<
    1、至少一次：消息不会丢失，但可能被重复处理(实现简单)
    2、最多一次：消息可能丢失可能会被处理，但最多只会被处理一次(实现简单)
    3、精确一次：消息被处理并且只会被处理一次(比较难实现)


Kafka中的Message是以topic为基本单位组织的，不同的topic之间是相互独立的。每个topic又可以分成几个不同的partition
(每个topic有几个partition是在创建topic时指定的)，每个partition存储一部分Message

partition是以文件的形式存储在文件系统中，比如，创建了一个名为page_visits的topic，其有5个partition，那么在Kafka的数据目录中
(由配置文件中的log.dirs指定的)中就有这样5个目录: page_visits-0， page_visits-1，page_visits-2，page_visits-3，page_visits-4，
其命名规则为<topic_name>-<partition_id>，里面存储的分别就是这5个partition的数据。

Partition中的每条Message由offset来表示它在这个partition中的偏移量，这个offset不是该Message在partition数据文件中的实际存储位置，而是逻辑上一个值，
它唯一确定了partition中的一条Message。因此，可以认为offset是partition中Message的id。

partition中的每条Message包含了以下三个属性：
     1.offset
     2.MessageSize
     3.data
     其中offset为long型，MessageSize为int32，表示data有多大，data为message的具体内容。它的格式和Kafka通讯协议中介绍的MessageSet格式是一致。


Kafka解决查询效率的手段之一是将数据文件分段，比如有100条Message，它们的offset是从0到99。假设将数据文件分成5段，第一段为0-19，第二段为20-39，
以此类推，每段放在一个单独的数据文件里面，数据文件以该段中最小的offset命名。这样在查找指定offset的Message的时候，
用二分查找就可以定位到该Message在哪个段中。
Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为.index


-------------
https://blog.csdn.net/gududedabai/article/details/80001523
-------------


........................................................... 

 <<<<<<<<<<<  kafka message 格式是什么样的?  >>>>>>>>>>>>>>>>>>>
一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成

header部分由一个字节的magic(文件格式)和四个字节的CRC32(用于判断body消息体是否正常)构成。

当magic的值为1的时候，会在magic和crc32之间多一个字节的数据：attributes(保存一些相关属性，比如是否压缩、压缩格式等等);

如果magic的值为0，那么不存在attributes属性

body是由N个字节构成的一个消息体，包含了具体的key/value消息
.............................


查看kafka版本命令:  find ./libs/ -name \*kafka_\* | head -1 | grep -o '\kafka[^\n]*' 

<<<<<<<<<<<<<<<   zookeeper在Kakfa中扮演的角色  >>>>>>>>>>>>>>>>>>>>>>>
Kafka将元数据信息保存在Zookeeper中，但是发送给Topic本身的数据是不会发到Zk上的，否则Zk就疯了。
kafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置。
broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新。
而客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整。
这样就保证了添加或去除broker时，各broker间仍能自动实现负载均衡。
这里的客户端指的是Kafka的消息生产端(Producer)和消息消费端(Consumer)Producer端使用zookeeper用来"发现"broker列表,
以及和Topic下每个partition的leader建立socket连接并发送消息。
也就是说每个Topic的partition是由Lead角色的Broker端使用zookeeper来注册broker信息,
以及监测partition leader存活性.Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,
同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息.
2.zookeeper中信息
![Aaron Swartz](2779043-ace9980fad0c49a4.png)




kafka项目启动报错： Error processing condition on org.springframework.boot.autoconfigure.kafka.KafkaAutoCon
启动时遇见报错

想到spring boot与kafka的兼容问题

原因：spring-boot 我用的是 2.0.0

改成 1.5.6 就可以了

<parent>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-parent</artifactId>
       <version>1.5.6.RELEASE</version>
   <relativePath/> <!-- lookup parent from repository -->
</parent>




kafka websocket 整合

<?xml version="1.0" encoding="UTF-8"?>
 <project xmlns="http://maven.apache.org/POM/4.0.0"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
     <modelVersion>4.0.0</modelVersion>
 
    <groupId>person</groupId>
     <artifactId>wbSocketkafka</artifactId>
     <version>1.0-SNAPSHOT</version>
 
     <dependencies>
         <!-- webSocket所需依赖 -->
         <dependency>
             <groupId>javax</groupId>
            <artifactId>javaee-api</artifactId>
             <version>7.0</version>
         </dependency>
         <!-- kafka 所需依赖 -->
         <dependency>
             <groupId>org.apache.kafka</groupId>
             <artifactId>kafka_2.9.2</artifactId>
             <version>0.8.1.1</version>
         </dependency>
         <dependency>
             <groupId>org.apache.kafka</groupId>
             <artifactId>kafka-clients</artifactId>
             <version>RELEASE</version>
         </dependency> 
     </dependencies>
 </project>


//此处定义接口的uri
 @ServerEndpoint("/wbSocket")
 public class WebSocket {
     private Session session;
     public static CopyOnWriteArraySet<WebSocket> wbSockets = new CopyOnWriteArraySet<WebSocket>(); //此处定义静态变量，以在其他方法中获取到所有连接
     
     /**
      * 建立连接。
      * 建立连接时入参为session
      */
     @OnOpen
     public void onOpen(Session session){
         this.session = session;
         wbSockets.add(this); //将此对象存入集合中以在之后广播用，如果要实现一对一订阅，则类型对应为Map。由于这里广播就可以了随意用Set
         System.out.println("New session insert,sessionId is "+ session.getId());
     }
     /**
      * 关闭连接
      */
     @OnClose
     public void onClose(){
         wbSockets.remove(this);//将socket对象从集合中移除，以便广播时不发送次连接。如果不移除会报错(需要测试)
         System.out.println("A session insert,sessionId is "+ session.getId());
     }
     /**
      * 接收前端传过来的数据。
      * 虽然在实现推送逻辑中并不需要接收前端数据，但是作为一个webSocket的教程或叫备忘，还是将接收数据的逻辑加上了。
      */
     @OnMessage
     public void onMessage(String message ,Session session){
         System.out.println(message + "from " + session.getId());
     }
 
     public void sendMessage(String message) throws IOException {
         this.session.getBasicRemote().sendText(message);
     }
 }

public class ConsumerKafka extends Thread {
 
     private KafkaConsumer<String,String> consumer;
     private String topic = "kafkaTopic";
 
     public ConsumerKafka(){
 
     }
 
     @Override
     public void run(){
         //加载kafka消费者参数
         Properties props = new Properties();
         props.put("bootstrap.servers", "localhost:9092");
         props.put("group.id", "ytna");
         props.put("enable.auto.commit", "true");
         props.put("auto.commit.interval.ms", "1000");
         props.put("session.timeout.ms", "15000");
         props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
         props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
         //创建消费者对象
         consumer = new KafkaConsumer<String,String>(props);
         consumer.subscribe(Arrays.asList(this.topic));
         //死循环，持续消费kafka
         while (true){
             try {
                //消费数据，并设置超时时间
                 ConsumerRecords<String, String> records = consumer.poll(100);
                 //Consumer message
                 for (ConsumerRecord<String, String> record : records) {
                     //Send message to every client
                     for (WebSocket webSocket :wbSockets){
                         webSocket.sendMessage(record.value());
                     }
                 }
             }catch (IOException e){
                 System.out.println(e.getMessage());
                 continue;
             }
         }
     }
 
     public void close() {
         try {
             consumer.close();
         } catch (Exception e) {
             System.out.println(e.getMessage());
         }
     }
 
     //供测试用，若通过tomcat启动需通过其他方法启动线程
     public static void main(String[] args){
         ConsumerKafka consumerKafka = new ConsumerKafka();
         consumerKafka.start();
     }
 }

<!DOCTYPE html>
 <html lang="en">
 <head>
     <meta charset="UTF-8">
     <title>WebSocket client</title>
     <script type="text/javascript">
         var socket;
         if (typeof (WebSocket) == "undefined"){
             alert("This explorer don't support WebSocket")
         }
 
         function connect() {
             //Connect WebSocket server
             socket =new WebSocket("ws://127.0.0.1:8080/wbSocket");
             //open
             socket.onopen = function () {
                 alert("WebSocket is open");
             }
             //Get message
             socket.onmessage = function (msg) {
                 alert("Message is " + msg);
             }
             //close
             socket.onclose = function () {
                 alert("WebSocket is closed");
             }
             //error
             socket.onerror = function (e) {
                 alert("Error is " + e);
             }
         }
 
         function close() {
             socket.close();
         }
 
         function sendMsg() {
             socket.send("This is a client message ");
         }
     </script>
 </head>
 <body>
     <button onclick="connect()">connect</button>
     <button onclick="close()">close</button>
     <button onclick="sendMsg()">sendMsg</button>
 </body>
 </html>
 
